# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MgDpc0X5gxtUQiCQkJT8KcqKiWj3mdEH
"""

!pip install spacy
!pip install newsapi-python

!python -m spacy download en_core_web_lg



nlp_eng = en_core_web_lg.load()
newsapi = NewsApiClient (api_key='87c3ca2bc53a45f98a654c6f9689b0f7')



temp = newsapi.get_everything(q='coronavirus', language='en', from_param='2020-02-03', to='2020-03-03', sort_by='relevancy', page=pagina)

filename = 'articlesCOVID.pckl'
pickle.dump(articles, open(filename, 'wb'))filename = 'articlesCOVID.pckl'
loaded_model = pickle.load(open(filename, 'rb'))filepath = '/content/path/to/file/articlesCOVID.pckl'
pickle.dump(loaded_model, open(filepath, 'wb'))

for i, article in enumerate(articles):
    for x in article['articles']:
        title = x['title']
        description = x['description']
        content = x['content']
        dados.append({'title':titles[0], 'date':dates[0], 'desc':descriptions[0], 'content':content})df = pd.DataFrame(dados)
df = df.dropna()
df.head()

if (token.text in nlp_eng.Defaults.stop_words or token.text in punctuation):
  continue
if (token.pos_ in pos_tag):
  result.append(token.text)return result

for content in df.content.values:
    results.append([('#' + x[0]) for x in Counter(get_keywords_eng(content)).most_common(5)])df['keywords'] = results

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()